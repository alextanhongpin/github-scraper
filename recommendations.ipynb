{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "count_vec = CountVectorizer()\n",
    "cached_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "input_file = 'db/repos' # The file to load the user's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utils function\n",
    "def xstr(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    return s\n",
    "\n",
    "def load_data(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def jaccard_similarity(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "\n",
    "def process_keyword(keywords):\n",
    "    # Remove special characters\n",
    "    keywords = re.sub('\\W+', ' ', keywords)\n",
    "    \n",
    "    # Split string at uppercase\n",
    "    uppercase = re.findall('[A-Z][^A-Z]*', keywords)\n",
    "    if len(uppercase) > 0:\n",
    "        keywords = ' '.join(uppercase)\n",
    "        # If everything is lowercase, it will return empty array\n",
    "\n",
    "    # Convert to lowercase and split by white spaces\n",
    "    keywords = keywords.lower().split(' ') \n",
    "\n",
    "    # Remove empty string\n",
    "    keywords = [key for key in keywords if key != '']\n",
    "    \n",
    "    # Remove stopwords\n",
    "    keywords = [key for key in keywords if key not in cached_stopwords]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 42817 repos\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = load_data(input_file)\n",
    "data_len = len(data)\n",
    "print('loaded {} repos'.format(data_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output vector\n"
     ]
    }
   ],
   "source": [
    "\n",
    "items = {} # Dictionary mapping for all the items (repos)\n",
    "users = {} # Dictionary mapping for the user\n",
    "\n",
    "def populate_data(users, items, item):\n",
    "    login = item['owner']['login']\n",
    "    \n",
    "    # Cache the user's data\n",
    "    if users.get(login) is None:\n",
    "        users[login] = item['owner']\n",
    "\n",
    "    # Cache the repo's data\n",
    "    if items.get(login) is None:\n",
    "        items[login] = []\n",
    "    if item['fork']:\n",
    "        return\n",
    "    # Get the relevant fields\n",
    "    name = xstr(item['name'])\n",
    "    description = xstr(item['description'])\n",
    "    language = xstr(item['language'])\n",
    "    repo = 'uniquerepoidentifierx00' # Use this unique keyword as the repo count\n",
    "\n",
    "    # Get the whole text for matching\n",
    "    keywords = ' '.join([name, description, language, repo])\n",
    "    \n",
    "    keywords = process_keyword(keywords)\n",
    "    \n",
    "    # Second tuple\n",
    "    [items[login].append(key) for key in keywords]\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(populate_data, users, items, item) for item in data]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "\n",
    "# Handle the count vector first\n",
    "out = count_vec.fit_transform([' '.join(items[item]) \n",
    "                               for key, item in enumerate(items)]).toarray()\n",
    "\n",
    "jaccard_scores = [items[item] for key, item in enumerate(items)]\n",
    "print('Generated output vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks: [('alextanhongpin', [('TimurKiyivinski', 1.0252474478872371), ('scr1p7ed', 1.00483163785239), ('erikdubbelboer', 0.99467451581015698), ('FeliciousX', 0.99006737654851718), ('geoyws', 0.98220280375288205), ('Mwarukason', 0.98121602678842335), ('winfredselwyn', 0.97800580466345788), ('rahman541', 0.97473793194589864)])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logins = [item for key, item in enumerate(items)]\n",
    "\n",
    "def compute_scores(user1, items, out):\n",
    "    scores = {}\n",
    "    user1_index = logins.index(user1)\n",
    "    for user2_index, user2 in enumerate(items):\n",
    "        # Calculate score against other user only\n",
    "        if user1 != user2:\n",
    "            # Compute similarity scores\n",
    "            score1 = cosine_similarity([out[user1_index]], [out[user2_index]]).flatten()[0]\n",
    "            score2 = jaccard_similarity(jaccard_scores[user1_index], jaccard_scores[user2_index])\n",
    "            score = score1 + score2\n",
    "        \n",
    "        if scores.get(user1) is None:  \n",
    "            scores[user1] = []\n",
    "        scores[user1].append((user2, score))\n",
    "    return scores\n",
    "\n",
    "def rank_scores(scores):\n",
    "    ranks = []\n",
    "    for i, user in enumerate(scores):\n",
    "        top_n = sorted(scores[user], key=lambda tup: tup[1], reverse=True)[:8]\n",
    "        non_zero = [(user, score) for (user, score) in top_n if score != 0]\n",
    "        if (len(non_zero) > 0):\n",
    "            ranks.append((user, non_zero))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "scores = compute_scores('alextanhongpin', items, out)\n",
    "ranks = rank_scores(scores)\n",
    "print('ranks:', ranks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict similarity between keywords and the items in the dataset\n",
    "\n",
    "def search_keyword(keyword, out):\n",
    "    X = count_vec.transform(process_keyword(keyword))\n",
    "\n",
    "    scores = [(i, cosine_similarity(X, [value]).flatten()[0])\n",
    "              for i, value in enumerate(out)]\n",
    "\n",
    "    top_10_similar = sorted(scores, \n",
    "                            key=lambda tup: tup[1], \n",
    "                            reverse=True)[:10]\n",
    "    non_zero_scores = [(logins[index], score) \n",
    "                       for (index, score) in top_10_similar \n",
    "                       if score != 0]\n",
    "    return non_zero_scores\n",
    "\n",
    "keywords = {}\n",
    "def cached_search_keyword(keyword, keywords, out):\n",
    "    if keywords.get(keyword) is None:\n",
    "        keywords[keyword] = search_keyword(keyword, out)\n",
    "    return keywords[keyword]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rickysoo', 0.57735026918962584), ('jad5494', 0.5), ('GuubsFlow', 0.5), ('maelpengerang', 0.30151134457776363), ('hydertech', 0.23570226039551587), ('ruhaizat', 0.15430334996209191), ('kamudrikah', 0.11396057645963795), ('baimhanifkamil', 0.059028133610095526), ('jk-gan', 0.051969970033474297), ('wilz5363', 0.051164451009665081)]\n",
      "[('purnima23', 0.028501713717057404)]\n",
      "[('izambasiron', 0.1690308509457033)]\n",
      "[('jktan0504', 0.22360679774997896)]\n",
      "[('shahril96', 0.035944257734479471), ('SalocinDotTEN', 0.035759926992607577)]\n",
      "[('JoeSee', 0.36514837167011072), ('cafreyma', 0.34299717028501764), ('almez', 0.27617238536949701), ('Zulox', 0.16064386578049977), ('jwchong93', 0.087038827977848926), ('eileenwong9305', 0.080845208345444328), ('nazebzurati', 0.068358592702466331), ('cshong0618', 0.066964953018242512), ('YiiKuoChong', 0.062622429108514954), ('roninprogrammer', 0.059976014390406722)]\n",
      "[('cincauhangus', 0.2581988897471611), ('HazeWatchApp', 0.19802950859533489), ('sinclair83', 0.18257418583505536), ('putera', 0.13483997249264842), ('blackhair', 0.10369516947304253), ('ijat', 0.10136060675992289), ('shafdanny', 0.076471911290187253), ('hymns', 0.075377836144440907), ('shafiqsaaidin', 0.07124704998790965), ('Zerocchi', 0.059339082909692663)]\n",
      "[]\n",
      "[('ndhaniff', 0.11995202878081344), ('apitlekays', 0.098058067569092022)]\n",
      "[('ck-yap', 0.30151134457776363), ('bruceoutdoors', 0.036345618209240697)]\n",
      "[('jincongho', 0.067153427787307457)]\n",
      "[('JYYYYYLim', 0.035114749361031178)]\n",
      "[('brandonccy', 0.30151134457776363), ('cylim', 0.058370840541777901), ('egslava', 0.017697036260052198), ('SmallRoomLabs', 0.010490344148203601), ('jorcus', 0.010256545123110543)]\n",
      "[('footballpro20', 0.44721359549995793), ('tajulsharby', 0.27735009811261457), ('evangel4real', 0.16666666666666666), ('ikttan', 0.068680281974344518), ('oshinyil', 0.050702012656339383)]\n",
      "[('AsyrafHussin', 0.048621663832631515)]\n",
      "[('ASFnetwork', 0.094915799575249898), ('kidino', 0.028455519661223609)]\n",
      "[('sarawakreport', 0.28867513459481292), ('azrinaziz', 0.16439898730535729), ('Zyten', 0.10314212462587934), ('tariqk', 0.082199493652678646), ('adikadashrieq', 0.073720978077448568), ('limhenry', 0.025751310131230238), ('Sinar', 0.018922737716449093)]\n",
      "[('nikahmadz', 0.064282434653322507)]\n",
      "[('mypapit', 0.01749546270271593)]\n",
      "[('archie-lab', 0.092548962676549509), ('honnamkuan', 0.050832856777534893)]\n",
      "[('puven12', 0.12309149097933272)]\n",
      "[('mrf345', 0.055555555555555552)]\n",
      "[('chinloongtan', 0.094072086838359728), ('cchitsiang', 0.035828718195000928)]\n",
      "[('ahmedmusawir', 0.0099150937342689476)]\n",
      "[('usamakhalil86', 0.21320071635561041)]\n",
      "[('kennedywai', 0.21538744758532144), ('fheinrichs', 0.21320071635561041), ('exomarc', 0.20519567041703082), ('tohjg', 0.14285714285714285), ('Huiwenng', 0.13867504905630729), ('yusriy', 0.074639337086207597), ('Aryailia', 0.042562826537937429)]\n",
      "[('wikichua', 0.049751859510499458)]\n",
      "[('akusegan', 0.10259783520851541)]\n",
      "[('torabian', 0.44721359549995793), ('muhamadamin93', 0.31622776601683794), ('sunwaytechclub', 0.3065696697424829), ('nysnatuss', 0.2857142857142857), ('vaibhavg12', 0.20412414523193154), ('choongyouqi', 0.15811388300841897), ('thevenmuthu', 0.15811388300841897), ('LeonellS', 0.13102435641608368), ('AzimsTech', 0.12216944435630522), ('nitemarket', 0.11867816581938533)]\n",
      "[('syahmiibrahim', 0.027863910628767641)]\n",
      "[('skychew', 0.13130643285972254)]\n",
      "[('roninprogrammer', 0.059976014390406722)]\n",
      "[('Tester2009', 0.032808935746239332), ('inigoconsulting', 0.027461751819054487), ('eugene-eeo', 0.0084018781977456044)]\n",
      "[('ShadOoW', 0.099014754297667443)]\n",
      "[('d12santosh', 0.28284271247461901), ('trkrameshkumar', 0.045221563164613454), ('bruceoutdoors', 0.036345618209240697)]\n",
      "[('razinbunsu', 0.13736056394868904)]\n",
      "[('Asami1997', 0.0088603193990064548)]\n",
      "[('Ezek19', 0.074124931666110117)]\n",
      "[('contrepoint', 0.043033148291193521), ('zulhfreelancer', 0.031389959190638139)]\n",
      "[('alidrus', 0.125), ('junyuenlim', 0.031053504702226845)]\n"
     ]
    }
   ],
   "source": [
    "# new_set = set([])\n",
    "\n",
    "# for keyword in jaccard_scores:\n",
    "#     for key in keyword:\n",
    "#         new_set.add(key) \n",
    "\n",
    "# new_list = list(new_set)\n",
    "\n",
    "# Train the cache lol\n",
    "# for key in new_list:\n",
    "#     print('caching', key)\n",
    "#     cached_search_keyword(key, keywords, out)\n",
    "\n",
    "# Cache parallel\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     futures = [executor.submit(cached_search_keyword, key, keywords, out) for key in new_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cached_search_keyword('trace', keywords, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
