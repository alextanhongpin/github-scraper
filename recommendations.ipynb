{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "count_vec = CountVectorizer()\n",
    "cached_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "input_file = 'db/repos' # The file to load the user's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utils function\n",
    "def xstr(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    return s\n",
    "\n",
    "def load_data(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 42817 repos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = load_data(input_file)\n",
    "data_len = len(data)\n",
    "print('loaded {} repos'.format(data_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output vector\n"
     ]
    }
   ],
   "source": [
    "\n",
    "items = {} # Dictionary mapping for all the items (repos)\n",
    "users = {} # Dictionary mapping for the user\n",
    "\n",
    "def populate_data(users, items, item):\n",
    "    login = item['owner']['login']\n",
    "    \n",
    "    # Cache the user's data\n",
    "    if users.get(login) is None:\n",
    "        users[login] = item['owner']\n",
    "\n",
    "    # Cache the repo's data\n",
    "    if items.get(login) is None:\n",
    "        items[login] = []\n",
    "\n",
    "    # Get the relevant fields\n",
    "    name = xstr(item['name'])\n",
    "    description = xstr(item['description'])\n",
    "    language = xstr(item['language'])\n",
    "    repo = 'uniquerepoidentifierx00' # Use this unique keyword as the repo count\n",
    "\n",
    "    # Get the whole text for matching\n",
    "    keywords = ' '.join([name, description, language, repo])\n",
    "    \n",
    "    # Remove special characters\n",
    "    keywords = re.sub('\\W+', ' ', keywords)\n",
    "\n",
    "    # Convert to lowercase and split by white spaces\n",
    "    keywords = keywords.lower().split(' ') \n",
    "\n",
    "    # Remove empty string\n",
    "    keywords = [key for key in keywords if key != ''] \n",
    "    \n",
    "    # Remove stopwords\n",
    "    keywords = [key for key in keywords if key not in cached_stopwords]\n",
    "\n",
    "    # Second tuple\n",
    "    [items[login].append(key) for key in keywords]\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(populate_data, users, items, item) for item in data]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "\n",
    "# Handle the count vector first\n",
    "out = count_vec.fit_transform([' '.join(items[item]) \n",
    "                               for key, item in enumerate(items)]).toarray()\n",
    "\n",
    "print('Generated output vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks: [('piyushchauhan2011', [('satnami', 0.90832321636825097), ('geoyws', 0.89828810631359146), ('kanasite', 0.89718458519748157), ('cchongXD', 0.89596526897386686), ('lbthomsen', 0.89540610021274669), ('dhilip89', 0.89514675690099588), ('ethanliew', 0.89277611401200141), ('OskarAhl', 0.89262847200753215)])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logins = [item for key, item in enumerate(items)]\n",
    "\n",
    "def compute_scores(user1, items, out):\n",
    "    scores = {}\n",
    "    user1_index = logins.index(user1)\n",
    "    for user2_index, user2 in enumerate(items):\n",
    "        # Calculate score against other user only\n",
    "        if user1 != user2:\n",
    "            # Compute similarity scores\n",
    "            score = cosine_similarity([out[user1_index]], [out[user2_index]]).flatten()[0]\n",
    "        \n",
    "        if scores.get(user1) is None:  \n",
    "            scores[user1] = []\n",
    "        scores[user1].append((user2, score))\n",
    "    return scores\n",
    "\n",
    "def rank_scores(scores):\n",
    "    ranks = []\n",
    "    for i, user in enumerate(scores):\n",
    "        top_n = sorted(scores[user], key=lambda tup: tup[1], reverse=True)[:8]\n",
    "        non_zero = [(user, score) for (user, score) in top_n if score != 0]\n",
    "        if (len(non_zero) > 0):\n",
    "            ranks.append((user, non_zero))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "scores = compute_scores('piyushchauhan2011', items, out)\n",
    "ranks = rank_scores(scores)\n",
    "print('ranks:', ranks)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
